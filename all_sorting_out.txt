time="2024-09-28T22:35:44-05:00" level=warning msg="/Users/slijeff/Workspace/school/cs511/cs511p1/cs511p1-compose.yaml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
24/09/29 03:35:45 INFO SparkContext: Running Spark version 3.4.1
24/09/29 03:35:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/29 03:35:45 INFO ResourceUtils: ==============================================================
24/09/29 03:35:45 INFO ResourceUtils: No custom resources configured for spark.driver.
24/09/29 03:35:45 INFO ResourceUtils: ==============================================================
24/09/29 03:35:45 INFO SparkContext: Submitted application: sorting
24/09/29 03:35:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/09/29 03:35:45 INFO ResourceProfile: Limiting resource is cpu
24/09/29 03:35:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/09/29 03:35:46 INFO SecurityManager: Changing view acls to: root
24/09/29 03:35:46 INFO SecurityManager: Changing modify acls to: root
24/09/29 03:35:46 INFO SecurityManager: Changing view acls groups to: 
24/09/29 03:35:46 INFO SecurityManager: Changing modify acls groups to: 
24/09/29 03:35:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
24/09/29 03:35:46 INFO Utils: Successfully started service 'sparkDriver' on port 35235.
24/09/29 03:35:46 INFO SparkEnv: Registering MapOutputTracker
24/09/29 03:35:46 INFO SparkEnv: Registering BlockManagerMaster
24/09/29 03:35:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/29 03:35:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/29 03:35:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/29 03:35:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-043276c5-ece7-4f39-92ba-af535cf44225
24/09/29 03:35:46 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/09/29 03:35:46 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/29 03:35:46 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/09/29 03:35:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://main:7077...
24/09/29 03:35:46 INFO TransportClientFactory: Successfully created connection to main/172.17.0.2:7077 after 18 ms (0 ms spent in bootstraps)
24/09/29 03:35:46 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240929033546-0007
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240929033546-0007/0 on worker-20240929033351-172.17.0.2-43835 (172.17.0.2:43835) with 8 core(s)
24/09/29 03:35:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20240929033546-0007/0 on hostPort 172.17.0.2:43835 with 8 core(s), 1024.0 MiB RAM
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240929033546-0007/1 on worker-20240929033358-172.17.0.4-46817 (172.17.0.4:46817) with 8 core(s)
24/09/29 03:35:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20240929033546-0007/1 on hostPort 172.17.0.4:46817 with 8 core(s), 1024.0 MiB RAM
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240929033546-0007/2 on worker-20240929033358-172.17.0.3-41583 (172.17.0.3:41583) with 8 core(s)
24/09/29 03:35:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20240929033546-0007/2 on hostPort 172.17.0.3:41583 with 8 core(s), 1024.0 MiB RAM
24/09/29 03:35:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35471.
24/09/29 03:35:46 INFO NettyBlockTransferService: Server created on main:35471
24/09/29 03:35:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/29 03:35:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, main, 35471, None)
24/09/29 03:35:46 INFO BlockManagerMasterEndpoint: Registering block manager main:35471 with 366.3 MiB RAM, BlockManagerId(driver, main, 35471, None)
24/09/29 03:35:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, main, 35471, None)
24/09/29 03:35:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, main, 35471, None)
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240929033546-0007/0 is now RUNNING
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240929033546-0007/1 is now RUNNING
24/09/29 03:35:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240929033546-0007/2 is now RUNNING
24/09/29 03:35:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
